# 实验三 Huffman编码
## 一.实验原理

本次实验的实验原理是无失真信源编码的哈夫曼编码。由信息论相关知识可知，编码后平均码长的下界是信源熵，通过哈夫曼编码，平均码长可以接近下界并且编出来的码是一种即时码。哈夫曼编码由两种方式，一种是构建一颗二叉树来获得每一个信源符号唯一的码字，另一种构建三个数组，建立码字，符号，码长之间的关系，输出的码字直接查表即可，比建哈夫曼树这种方法要快很多。为了深入理解哈夫曼编码以及二叉树这种数据结构，该实验采用的是第一种方法。

二叉树的结构如下图所示
```
root表示根节点;lc表示左孩子l;rl表示右孩子
     root
    /    \
   lc     rc  
```

树上的每个节点我们用一个结构体表示：
```cpp
struct Node{
	Node *parent, *l_child, *r_child;
	BYTE data;
	int cnt;
	int code_len;
	bool is_leaf;
	char code[20];
	Node(){
		parent = NULL;
		l_child = NULL;
		r_child = NULL;
		data = '0';
		cnt = 0;
		is_leaf = false;
	}
	Node(Node *p, Node *l, Node*r, BYTE ch, int num, bool leaf){
		parent = p;
		l_child = l;
		r_child = r;
		data = ch;
		cnt = num;
		is_leaf = leaf;
	}
};
```
该结构体里面包括左右孩子和父亲（方便以链表的形式构建树）；该节点对应的字符，如果不是叶子结点，字符为空；码字和码长，方便统计和获得编码后输出文件；是否是叶子结点，为了树的遍历；以及默认构造函数和带参数的构造函数。

## 二.实验步骤

+ 首先对读入的字符进行频率统计(字符取值是[0, 255])，并记录总的字符数。同时，我们new一个该字符对应的结点。
+ 接着利用已有的结点，根据哈夫曼树的构建规则构建这课二叉树。
+ 然后再读一遍输入文件，对每个字符进行编码，并输出到编码后的文件。
+ 最后，计算信源的熵，编码后的平均码长，压缩比，并将频率，码长，码字等信息输出到txt文件中，导入exel，绘制成表格。

## 三.关键代码

在这里，我仅对关键代码进行分析。
+ 以二进制的形式读入文件，每次读一个字符，在读入文件的同时new一个结构体，并赋值。这里我用了一个结构体指针数组，并以0到255的值作为下标，这样就可以O(1)的速度找到该字符对应的结构体，非常方便！比如读入的字符是'a'，那么index[(int)a]就是a字符对应的结构体的指针。
```cpp
input_file = fopen(in_name, "rb"); //rb模式 而不是r模式！！！
if(!input_file){
	cout << "can not open file" << endl;
	return 0;
}
while((c = fgetc(input_file)) != EOF){
	if(!index[c]){
		Node *node = new Node();
		index[c] = node;
		node->data = c;
		node->is_leaf = true;
	}
	(index[c]->cnt)++;
	total_cnt++;
}
```
+ 在构建哈夫曼树的时候，我利用了优先队列这种数据结构。我们知道，构建哈夫曼树需要对字符频率进行排序， 然后每次取频率最小和次小的两个字符作为叶子结点，时间复杂度是O(nlogn)，但是如果我用优先队列去维护当前待排序的元素，我既能方便的获得评率最小和次小的两个字符，时间复杂也会降低，是O(logn)。通过以下几行代码，一颗哈夫曼树就构建完成了。
```cpp
for(int i = 0; i < 256; i++){
	if(index[i]) pq.push(index[i]);//把文件中存在的字符放入优先队列中
}
while(pq.size() != 1){
	Node *left = pq.top(); pq.pop();
	Node *right = pq.top();pq.pop();
	Node *fa = new Node(NULL, right, left, '0', (left->cnt) + (right->cnt), false);
	left->parent = fa; right->parent = fa;
	pq.push(fa);//把new出来的父亲结点放入优先队列中
}
```
+ 构建完哈夫曼树后，这时优先队列中只剩下树的根节点，我们把它pop()出来，在后续遍历的过程中会用到。获得码字的方式是遍历二叉树。若规定左0右1，我们构建好的这课二叉树的结构示意图如下
```
	root
       /    \
      0      1(d)
    /   \      
   0     1(c) 
 /   \
0(a)  1(b)     
```
在这棵树中，只有叶子结点表示文件中出现过的字符（括号中的字符）。比如当前读进来的字符是'a'，那么，我从root开始dfs，以找到该结点在树中的位置。找到该位置后，通过父亲节点往上回溯，这样一定会回溯到根节点（因为树中根节点到叶子的路径一定是唯一的），从而得到了该字符的码的**逆序**。注意，这里是逆序，所以还要对得到的码字进行翻转操作。代码如下
```cpp
void dfs_code(Node *now){
	if(now->is_leaf){//如果是叶子结点，生成码字
		gen_code(now);
		return ;
	}
	dfs_code(now->l_child);
	dfs_code(now->r_child);
	return ;
}

void gen_code(Node *leaf){
	int code_len = 0, idx = 0;
	Node *tem = leaf;
	while(tem -> parent != NULL){//如果不是根节点，往上回溯
		Node *p = tem->parent;
		if (tem == p->r_child) leaf->code[idx++] = '1';
		else leaf->code[idx++] = '0';
		tem = p;
		code_len++;//回溯的过程中记录次数，这就是码长
	}
	char *str = leaf->code;
	str[idx] = '\0';
	int len = strlen(str);
	for (int i = 0; i < len / 2 ; i++) {//这里进行了字符串翻转操作
		swap(str[i], str[len - i - 1]);
	}
	index[leaf->data]->code_len = code_len;
}
```
+ 通过以上操作，我们获得了每个字符对应的码字，但这还不够，我们还要将编码后的字符出入到文件中。注意，这里我们获得的是01字符串，但实际要输出文件中应该是01比特流，那么我们怎么将字符串转换成比特流呢？方法是把01字符串当做二进制处理，如果最后总长度不是8的倍数(一个字节8bit)补0，具体代码如下
```cpp
input_file = fopen(in_name, "rb");//再读一遍文件
memset(out_stream, 0, sizeof(out_stream));
int idx = 0, org_idx;
while ((c = fgetc(input_file)) != EOF) {
	char *str = index[c]->code;
	int len = index[c]->code_len;
	for (int j = 0; j < len; j++) out_stream[idx++] = str[j];//输出流字符串赋值
}
org_idx = idx;
out_stream[idx] = '\0';
if (idx % 8 != 0) {
	for (int i = idx; i < idx + 8 - (idx % 8); i++) {//不足补0
		out_stream[i] = '0';
	}
	idx += (8 - (idx % 8));
}

FILE *output_file;
output_file = fopen(out_name, "wb");
out = (BYTE*)malloc(idx / 8);
for (int i = idx - 1, j = 0; i >= 0; i -= 8) {
	int k = 8, base = 1, tem = i;
	while (k--) {
		out[j] += (BYTE) (base * (out_stream[tem] - '0'));//转换成unsigned char
		tem--;
		base *= 2;
	}
	j++;
}
fwrite(out, 1, idx / 8, output_file);//写入输出文件
```
至此，整个编码过程结束！

## 四.实验结果

实验结果在exel文件中，这里只给出最终的统计结果
![result](https://github.com/cucrui/Data-compression/blob/master/%E5%AE%9E%E9%AA%8C%E4%B8%89_Huffman%E7%BC%96%E7%A0%81/result.png)

## 五.实验结论

一开始得到上述结果的时候还怀疑是不是程序写错了，压缩率怎么这么低。分析后得知，哈夫曼的压缩比和信源的概率分布由极大的关系，比如像doc，pdf这样的文本文件，有些字符出的频率极高，这样就就可以分配很短的码字，而有些文件，信源概率分布非常均匀，这样压缩之后压缩比救护很低。这也是为什么熵编码要放在信源编码的最后一步，因为通过前面的一些操作，比如说变换，量化，信源的概率分布变得非常不均匀，这是熵编码最喜欢的概率分布，也就能使压缩比大大提高了！


